---
title: "Evaluation Analysis"
# output: html_notebook
output: rmarkdown::github_document
---

# Data Setup

```{r load libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(here)
library(jsonlite)
library(ggpubr)
library(lme4)
library(lmerTest)
theme_set(theme_bw())
```

```{r load data, message=FALSE, warning=FALSE}

df_clipscores_cosid = read_csv(here("metrics", "clipscore", "results", "cosid-clipscores.csv")) %>% 
  # remove attention checks
  filter(imgstem_version != "guitar",
         imgstem_version != "640px-parc_agen") %>% 
  separate(imgstem_version, into=c("imgstem", "version"), sep="_version") %>% 
  rename(description = texts) %>% 
  select(-text_controls)

df_spurtsmima_cosid = read_csv(here("metrics", "SPURTS", "results", "cosid-spurts-mima.csv")) %>% 
  # TODO: remove attention checks
  # filter(imgstem_version != "guitar",
  #        imgstem_version != "640px-parc_agen") %>%
  rename(description = texts) %>% 
  select(-text_controls)

df_clipscores_cosid_shuffled = read_csv(here("metrics", "clipscore", "results", "cosid-clipscores-shuffled.csv")) %>% 
  # remove attention checks
  filter(imgstem_version != "guitar",
         imgstem_version != "640px-parc_agen") %>% 
  separate(imgstem_version, into=c("imgstem", "version"), sep="_version") %>% 
  rename(description = texts) %>% 
  select(-text_controls)
  
df_blv_ratings = read_csv(here("behavioral_data", "blv_data_criticaltrials.csv"))

df_sighted_ratings = read_csv(here("behavioral_data", "sighted_data_criticaltrials.csv")) %>% 
  filter(description %in% unique(df_blv_ratings$description))

```

```{r prepare data, message=FALSE, warning=FALSE}

df_blv_avg = df_blv_ratings %>% 
  gather(question, response, q_irrelevance, q_reconstructivity, q_relevance, q_imgfit, q_overall) %>% 
  group_by(description, img_id, context, question) %>% 
  summarize(mean_response = mean(response),
            sd_response = sd(response)) %>% 
  ungroup()

df_sighted_avg = df_sighted_ratings %>% 
  gather(question, response, q_relevance.preimg, q_irrelevance.preimg, q_reconstructivity.preimg, q_overall.preimg, q_relevance.postimg, q_imgfit.preimg, q_imgfit.postimg, q_irrelevance.postimg, q_overall.postimg)  %>% 
  group_by(description, img_id, context, question) %>% 
  summarize(mean_response = mean(response),
            sd_response = sd(response)) %>% 
  ungroup()

df_human_data = df_blv_avg %>%
  rbind(df_sighted_avg)

df_clipscore_human_corr = df_human_data %>% 
  select(description, img_id, context, question, mean_response) %>% 
  merge(df_clipscores_cosid, by=c("description"))

df_spurtsmima_human_corr = df_human_data %>% 
  select(description, img_id, context, question, mean_response) %>% 
  merge(df_spurtsmima_cosid, by=c("description"))

```

# BLV--Sighted Correlation

```{r blv sighted corr, echo=FALSE, fig.height=4, fig.width=10.5, message=FALSE, warning=FALSE}
df_human_data %>% 
  separate(question, c("question", "img_visibility"), sep="\\.", remove=TRUE) %>% 
  mutate_at(vars(img_visibility), funs(ifelse(is.na(.), "blv_response", .))) %>% 
  select(question, description, img_visibility, "mean_response") %>% 
  spread(img_visibility, "mean_response") %>%
  gather(sighted_visibility, sighted_response, postimg, preimg) %>% 
  filter(!(question == "q_reconstructivity" & sighted_visibility == "postimg")) %>% 
  mutate_at(vars(question), funs(case_when(
    . == "q_overall" ~ "Overall",
    . == "q_relevance" ~ "Relevance",
    . == "q_irrelevance" ~ "Irrelevance",
    . == "q_reconstructivity" ~ "Imaginability",
    . == "q_imgfit" ~ "Fit",
    TRUE ~ "FIRE"
  ))) %>%
  mutate_at(vars(question), funs(fct_relevel(., c("Overall", "Imaginability", "Relevance", "Irrelevance", "Fit")))) %>%
  mutate_at(vars(sighted_visibility), funs(ifelse(.=="postimg", "visible", "not visible"))) %>%
  ggplot(., aes(x=blv_response, y=sighted_response, color=sighted_visibility)) +
    facet_wrap(~question, nrow = 1) +
    geom_jitter(alpha=0.2, size=2) +
    geom_line(stat="smooth",method = "lm",
              size = 2,
              alpha = 0.9) +
    stat_cor(method = "pearson", label.x.npc = "left", label.y.npc = 0.21) +
    scale_color_manual(values=c("#009E73", "#56B4E9")) +
    theme(strip.background = element_rect(color="white", fill="white"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.spacing = unit(1.5, "lines"),
          axis.title = element_text(size=17),
          axis.text = element_text(size=13),
          strip.text.x = element_text(size=17),
          legend.title = element_text(size=15),
          legend.text = element_text(size=15)) +
    theme(legend.position ="top") +
    ylab("Sighted participant ratings") +
    xlab("BLV participant ratings") +
    labs(color='Image visibility for sighted participants') 

# ggsave(here("analyses", "figures", "raw", "blv-sighted-corr.png"), width=13.5, height=4)
```

# Human--Length Correlations

```{r human length corr, echo=TRUE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}

###
# INDIVIDUAL DATA
###
# df_length_blv = df_blv_ratings %>% 
#   select(description, q_reconstructivity, q_relevance, q_irrelevance, q_overall) %>% 
#   gather(question, value, -description)
# 
# df_length_corr = df_sighted_ratings %>% 
#   select(description, q_reconstructivity.preimg, q_relevance.preimg, q_irrelevance.preimg, q_overall.preimg, q_relevance.postimg, q_irrelevance.postimg, q_overall.postimg) %>% 
#   gather(question, value, -description) %>% 
#   rbind(df_length_blv) %>% 
#   mutate(metric = case_when(
#     str_detect(question, "postimg") ~ "sighted_postimg",
#     str_detect(question, "preimg") ~ "sighted_preimg",
#     TRUE ~ "blv"
#   )) %>% 
#   mutate_at(vars(question), funs(str_replace(., "\\.(post|pre)img", ""))) %>% 
#   mutate_at(vars(value), funs(./5))


###
# AVERAGED DATA
###
df_length_corr = df_human_data %>%
  rename(value = mean_response) %>%
  mutate(metric = case_when(
    str_detect(question, "postimg") ~ "sighted_postimg",
    str_detect(question, "preimg") ~ "sighted_preimg",
    TRUE ~ "blv"
  )) %>%
  mutate_at(vars(question), funs(str_replace(., "\\.(post|pre)img", ""))) %>%
  mutate_at(vars(value), funs(./5))


df_length_corr_overall = df_length_corr %>% 
  filter(question == "q_overall") %>%
  select(description, metric, value) %>% 
  mutate(descr_length = str_length(description)) %>% 
  mutate(facet_cond = "Overall")

df_length_corr_reconstr = df_length_corr %>% 
  filter(question == "q_reconstructivity") %>%
  select(description, metric, value) %>% 
  mutate(descr_length = str_length(description)) %>% 
  mutate(facet_cond = "Imaginability")

df_length_corr_imgfit = df_length_corr %>% 
  filter(question == "q_imgfit") %>%
  select(description, metric, value) %>% 
  mutate(descr_length = str_length(description)) %>% 
  mutate(facet_cond = "Fit")

df_length_corr_rel = df_length_corr %>% 
  filter(question == "q_relevance") %>%
  select(description, metric, value) %>% 
  mutate(descr_length = str_length(description)) %>% 
  mutate(facet_cond = "Relevance")

df_length_corr_irrel = df_length_corr %>% 
  filter(question == "q_irrelevance") %>%
  select(description, metric, value) %>% 
  mutate(descr_length = str_length(description)) %>% 
  mutate(facet_cond = "Irrelevance")

df_length_corr_overall %>% 
  rbind(df_length_corr_reconstr) %>%
  # rbind(df_length_corr_imgfit) %>%
  rbind(df_length_corr_rel) %>%
  rbind(df_length_corr_irrel) %>%
  filter(metric %in% c("blv", "sighted_preimg", "sighted_postimg")) %>%
  # filter(metric %in% c("clipscore", "SPURTS_score")) %>%
  mutate_at(vars(facet_cond), funs(fct_relevel(., c("Overall", "Imaginability", "Relevance", "Irrelevance")))) %>%
  ggplot(., aes(x=descr_length, y=value, color=metric)) +
    facet_wrap(~facet_cond, nrow=2) +
    geom_point(alpha=0.2, position=position_jitter(width=0, height=0.07)) +
    theme(legend.position = "top") +
    geom_line(stat="smooth",method = "lm",
              size = 2,
              alpha = 0.8) +
    scale_color_manual(values=c("#E69F00", "#56B4E9", "#009E73")) +
    # scale_color_manual(values=c("black", "grey")) +
    theme(strip.background =element_rect(color="white", fill="white"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.spacing = unit(1.5, "lines"),
          axis.title = element_text(size=15),
          axis.text = element_text(size=13),
          strip.text.x = element_text(size = 18),
          legend.title = element_text(size=13),
          legend.text = element_text(size=11)) +
    coord_cartesian(ylim=c(0,1)) +
    stat_cor(method = "pearson", label.x.npc = "middle", label.y.npc = 0.3) +
    scale_y_continuous(breaks = c(0, 0.5, 1)) +
    scale_x_continuous(breaks = c(0, 250, 500)) +
    xlab("Description length") +
    ylab("Rating")

# ggsave(here("analyses", "figures", "raw", "human_length_corr.png"), height=6.3, width=7.5)
```

# Clipscore Compatibility

```{r clipscore compatibility, echo=TRUE, fig.height=4, fig.width=5.5, message=FALSE, warning=FALSE}

df_clipscores_cosid %>% 
  mutate(condition = "in order") %>% 
  rbind(mutate(df_clipscores_cosid_shuffled, condition = "shuffled")) %>% 
  ggplot(., aes(x=condition, y=clipscore)) +
    geom_point(alpha=0.4, position=position_jitter(height=0, width=0.2)) + 
    stat_summary(fun = "mean", 
                 position = position_dodge(0.7),
                 size = 4,
                 geom = "point") +
    stat_summary(fun.data = "mean_cl_boot",
                 geom = "errorbar",
                 position = position_dodge(0.7),
                 size = .4,
                 width = 0.3) +
    theme(strip.background =element_rect(color="white", fill="white"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.title = element_text(size=13),
          axis.text = element_text(size=11)) +
    scale_y_continuous(breaks = c(0, 0.5, 1)) +
    coord_cartesian(ylim=c(0,1)) +
    ylab("Clipscore") +
    xlab("Image--Description Pairing")

df_clipscores_cosid %>% 
  mutate(condition = "in order") %>% 
  rbind(mutate(df_clipscores_cosid_shuffled, condition = "shuffled")) %>% 
  group_by(condition) %>% 
  summarize(avg_rating = mean(clipscore)) %>% 
  ungroup()

# ggsave(here("analyses", "figures", "raw", "clipscore-truthfulness.png"), height=2.5, width=2.7)

```

# Human--Clipscore Correlations

```{r human clipscore corr, echo=TRUE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}

clipscore_blvsighted_corr = df_clipscore_human_corr %>% 
  mutate(participant_group = case_when(
    str_detect(question, "preimg") ~ "sighted\n(image not visible)",
    str_detect(question, "postimg") ~ "sighted\n(image visible)",
    TRUE ~ "BLV"
  )) %>% 
  mutate(question_type = str_replace_all(question, "(.postimg|.preimg)", "")) %>% 
  mutate_at(vars(question_type), funs(case_when(
    . == "q_overall" ~ "Overall",
    . == "q_relevance" ~ "Relevance",
    . == "q_irrelevance" ~ "Irrelevance",
    . == "q_reconstructivity" ~ "Imaginability",
    . == "q_imgfit" ~ "Fit",
    TRUE ~ "FIRE"
  ))) %>% 
  mutate_at(vars(question_type), 
            funs(fct_relevel(., c(
              "Overall", 
              "Imaginability", 
              "Relevance", 
              "Irrelevance", 
              "Fit"
              )))) %>% 
  filter(question_type != "Fit")

clipscore_blvsighted_corr %>% 
  ggplot(., aes(x=mean_response, y=clipscore, color=participant_group)) +
  # ggplot(., aes(x=mean_response, y=clipscore, color=question_type)) +
    facet_wrap(~question_type, nrow=2) +
    # facet_wrap(~participant_group, nrow=1) +
    geom_jitter(alpha=0.1) +
    geom_line(stat="smooth",method = "lm",
              size = 1,
              alpha = 0.8) +
    stat_cor(method = "pearson", label.x.npc = "middle", label.y.npc = 0) +
    scale_color_manual(values=c("#E69F00", "#009E73", "#56B4E9")) +
    theme(strip.background =element_rect(color="white", fill="white"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.spacing = unit(1.5, "lines"),
          axis.title = element_text(size=15),
          axis.text = element_text(size=13),
          strip.text.x = element_text(size = 15),
          legend.title = element_text(size=13),
          legend.text = element_text(size=11)) +
    coord_cartesian(ylim=c(0,1), xlim=c(1,5)) +
    # coord_cartesian(xlim=c(1,5)) +
    theme(legend.position = "top") +
    xlab("Mean participant rating") +
    ylab("Clipscore") +
    labs(color='Participant group')  +
    scale_y_continuous(breaks = c(0, 0.5, 1))

# ggsave(here("analyses", "figures", "raw", "human_clipscore_corr.png"), height=5.5, width=6)

```

### Non-Averaged

```{r human clipscore corr nonavg, echo=TRUE, fig.height=4, fig.width=5, message=FALSE, warning=FALSE}

df_blv_ratings %>% 
  select(description, q_overall) %>% 
  merge(df_clipscores_cosid, by=c("description")) %>% 
  ggplot(., aes(x=q_overall, y=clipscore)) +
    geom_jitter(alpha=0.1) +
    geom_line(stat="smooth",method = "lm",
              size = 1,
              alpha = 0.8) +
    # coord_cartesian(ylim=c(0,1), xlim=c(1,5)) +
    stat_cor(method = "pearson", label.x.npc = "middle", label.y.npc = 0)

df_sighted_ratings %>% 
  filter(description %in% unique(df_blv_avg$description)) %>% 
  select(description, q_overall.preimg) %>% 
  merge(df_clipscores_cosid, by=c("description")) %>% 
  ggplot(., aes(x=q_overall.preimg, y=clipscore)) +
    geom_jitter(alpha=0.1) +
    geom_line(stat="smooth",method = "lm",
              size = 1,
              alpha = 0.8) +
    # coord_cartesian(ylim=c(0,1), xlim=c(1,5)) +
    stat_cor(method = "pearson", label.x.npc = "middle", label.y.npc = 0)

df_sighted_ratings %>% 
  filter(description %in% unique(df_blv_avg$description)) %>% 
  select(description, q_overall.postimg) %>% 
  merge(df_clipscores_cosid, by=c("description")) %>% 
  ggplot(., aes(x=q_overall.postimg, y=clipscore)) +
    geom_jitter(alpha=0.1) +
    geom_line(stat="smooth",method = "lm",
              size = 1,
              alpha = 0.8) +
    # coord_cartesian(ylim=c(0,1), xlim=c(1,5)) +
    stat_cor(method = "pearson", label.x.npc = "middle", label.y.npc = 0)


```

# Human--SPURTS / MIMA Correlations

```{r human spurts corr, echo=TRUE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}

spurtsmima_blvsighted_corr = df_spurtsmima_human_corr %>% 
  mutate(participant_group = case_when(
    str_detect(question, "preimg") ~ "sighted\n(image not visible)",
    str_detect(question, "postimg") ~ "sighted\n(image visible)",
    TRUE ~ "BLV"
  )) %>% 
  mutate(question_type = str_replace_all(question, "(.postimg|.preimg)", "")) %>% 
  mutate_at(vars(question_type), funs(case_when(
    . == "q_overall" ~ "Overall",
    . == "q_relevance" ~ "Relevance",
    . == "q_irrelevance" ~ "Irrelevance",
    . == "q_reconstructivity" ~ "Imaginability",
    . == "q_imgfit" ~ "Fit",
    TRUE ~ "FIRE"
  ))) %>% 
  mutate_at(vars(question_type), 
            funs(fct_relevel(., c(
              "Overall", 
              "Imaginability", 
              "Relevance", 
              "Irrelevance", 
              "Fit"
              )))) %>% 
  filter(question_type != "Fit")

spurtsmima_blvsighted_corr %>% 
  ggplot(., aes(x=mean_response, y=SPURTS_score, color=participant_group)) +
  # ggplot(., aes(x=mean_response, y=clipscore, color=question_type)) +
    facet_wrap(~question_type, nrow=2) +
    # facet_wrap(~participant_group, nrow=1) +
    geom_jitter(alpha=0.1) +
    geom_line(stat="smooth",method = "lm",
              size = 1,
              alpha = 0.8) +
    stat_cor(method = "pearson", label.x.npc = "middle", label.y.npc = 0.2) +
    scale_color_manual(values=c("#E69F00", "#009E73", "#56B4E9")) +
    theme(strip.background =element_rect(color="white", fill="white"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.spacing = unit(1.5, "lines"),
          axis.title = element_text(size=15),
          axis.text = element_text(size=13),
          strip.text.x = element_text(size = 15),
          legend.title = element_text(size=13),
          legend.text = element_text(size=11)) +
    coord_cartesian(ylim=c(0,.6), xlim=c(1,5)) +
    # coord_cartesian(xlim=c(1,5)) +
    theme(legend.position = "top") +
    xlab("Mean participant rating") +
    ylab("SPURTS") +
    labs(color='Participant group')  +
    scale_y_continuous(breaks = c(0, 0.5, 1))

# ggsave(here("analyses", "figures", "raw", "human_spurts_corr.png"), width = 6, height = 5.5)

###
# MIMA
###

# spurtsmima_blvsighted_corr %>% 
#   ggplot(., aes(x=mean_response, y=MIMA_score, color=participant_group)) +
#   # ggplot(., aes(x=mean_response, y=clipscore, color=question_type)) +
#     facet_wrap(~question_type, nrow=2) +
#     # facet_wrap(~participant_group, nrow=1) +
#     geom_jitter(alpha=0.1) +
#     geom_line(stat="smooth",method = "lm",
#               size = 1,
#               alpha = 0.8) +
#     stat_cor(method = "pearson", label.x.npc = "middle", label.y.npc = 0) +
#     scale_color_manual(values=c("#E69F00", "#009E73", "#0072B2")) +
#     theme(strip.background =element_rect(color="white", fill="white"),
#           panel.grid.major = element_blank(),
#           panel.grid.minor = element_blank(),
#           panel.spacing = unit(1.5, "lines"),
#           axis.title = element_text(size=15),
#           axis.text = element_text(size=13),
#           strip.text.x = element_text(size = 15),
#           legend.title = element_text(size=13),
#           legend.text = element_text(size=11)) +
#     coord_cartesian(ylim=c(0,1), xlim=c(1,5)) +
#     # coord_cartesian(xlim=c(1,5)) +
#     theme(legend.position = "top") +
#     xlab("Mean participant rating") +
#     ylab("MIMA") +
#     labs(color='Participant group')  +
#     scale_y_continuous(breaks = c(0, 0.5, 1))

```


# Metrics--Length Correlations

```{r metrics length corr, echo=TRUE, fig.height=4, fig.width=5.5, message=FALSE, warning=FALSE}

df_clips_prep = df_clipscores_cosid %>% 
  rename(value=clipscore) %>% 
  mutate(metric="clipscore") %>% 
  select(description, metric, value)

df_spurtsmima_prep = df_spurtsmima_cosid %>%
  gather(metric, value, SPURTS_score, MIMA_score) %>%
  select(description, metric, value)

df_clips_prep %>% 
  rbind(df_spurtsmima_prep) %>% 
  mutate(descr_length = str_length(description)) %>% 
  filter(metric %in% c("clipscore", "SPURTS_score")) %>% 
  ggplot(., aes(x=descr_length, y=value, color=metric)) +
    geom_point(alpha=0.2) +
    theme(legend.position = "top") +
    geom_line(stat="smooth",method = "lm",
              size = 2,
              alpha = 0.8) +
    scale_color_manual(values=c("black", "grey")) +
    theme(strip.background =element_rect(color="white", fill="white"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.spacing = unit(1.5, "lines"),
          axis.title = element_text(size=13),
          axis.text = element_text(size=11),
          strip.text.x = element_text(size = 18),
          legend.position = "none") +
    coord_cartesian(ylim=c(0,1)) +
    stat_cor(method = "pearson", label.x.npc = "middle", label.y.npc = 0.01) +
    scale_y_continuous(breaks = c(0, 0.5, 1)) +
    scale_x_continuous(breaks = c(0, 250, 500)) +
    xlab("Description length") +
    ylab("Score")

# ggsave(here("analyses", "figures", "raw", "metrics_length_corr.png"), height=2.5, width=3)
```

# Stats

### Context Effects in Human Evaluations

```{r stats human eval, echo=TRUE}

df_stats_blv_overall = df_blv_ratings %>% 
  select(description, q_overall, q_reconstructivity, q_relevance, q_irrelevance, participant) %>% 
  merge(df_clipscores_cosid, by=c("description")) %>% 
  merge(df_spurtsmima_cosid, by=c("description")) %>% 
  mutate(description_length = str_length(description)) %>%
  mutate(description_length_scaled = description_length / max(description_length)) %>%
  mutate(overall_rating = ((q_overall - 1) / 4)) %>% 
  mutate_at(vars(q_reconstructivity, q_relevance, q_irrelevance), funs(((. - 1) / 4))) %>% 
  mutate_at(vars(q_reconstructivity, q_relevance, q_irrelevance), funs(. - mean(.)))

f = overall_rating ~ q_irrelevance + q_reconstructivity + q_relevance + (1|participant) + (1|description)

m = lmer(f, df_stats_blv_overall)
summary(m)

df_stats_sighted_overall = df_sighted_ratings %>% 
  select(description, q_overall.preimg, q_reconstructivity.preimg, q_relevance.preimg, q_irrelevance.preimg, anon_worker_id) %>% 
  merge(df_clipscores_cosid, by=c("description")) %>% 
  merge(df_spurtsmima_cosid, by=c("description")) %>% 
  mutate(description_length = str_length(description)) %>%
  mutate(description_length_scaled = description_length / max(description_length)) %>%
  mutate(overall_rating = ((q_overall.preimg - 1) / 4)) %>% 
  mutate_at(vars(q_reconstructivity.preimg, q_relevance.preimg, q_irrelevance.preimg), funs(((. - 1) / 4))) %>% 
  mutate_at(vars(q_reconstructivity.preimg, q_relevance.preimg, q_irrelevance.preimg), funs(. - mean(.)))

f = overall_rating ~ q_reconstructivity.preimg + q_relevance.preimg + q_irrelevance.preimg + (1|anon_worker_id) + (1|description)

m = lmer(f, df_stats_sighted_overall)
summary(m)

df_stats_sighted_overall = df_sighted_ratings %>% 
  select(description, q_overall.postimg, q_reconstructivity.preimg, q_relevance.postimg, q_irrelevance.postimg, anon_worker_id) %>% 
  merge(df_clipscores_cosid, by=c("description")) %>% 
  merge(df_spurtsmima_cosid, by=c("description")) %>% 
  mutate(description_length = str_length(description)) %>%
  mutate(description_length_scaled = description_length / max(description_length)) %>%
  mutate(overall_rating = ((q_overall.postimg - 1) / 4)) %>% 
  mutate_at(vars(q_reconstructivity.preimg, q_relevance.postimg, q_irrelevance.postimg), funs(((. - 1) / 4))) %>% 
  mutate_at(vars(q_reconstructivity.preimg, q_relevance.postimg, q_irrelevance.postimg), funs(. - mean(.)))

f = overall_rating ~ q_reconstructivity.preimg + q_relevance.postimg + q_irrelevance.postimg + (1|anon_worker_id) + (1|description)

m = lmer(f, df_stats_sighted_overall)
summary(m)
```

### Clipscore Compatibility

```{r stats clipscore compat, echo=TRUE}

df_clipscorecomp_model = df_clipscores_cosid %>% 
  mutate(condition = "in order") %>% 
  rbind(mutate(df_clipscores_cosid_shuffled, condition = "shuffled")) %>% 
  mutate(cond_enc = ifelse(condition=="in order", 1, 0))

f = cond_enc ~ clipscore

m = lm(f, df_clipscorecomp_model)
summary(m)
  
```

### SPURTS Effect of Description Length 

```{r stats spurts effect, echo=TRUE}

df_stats_blv_overall = df_blv_ratings %>% 
  select(description, q_overall, participant) %>% 
  merge(df_clipscores_cosid, by=c("description")) %>% 
  merge(df_spurtsmima_cosid, by=c("description")) %>% 
  mutate(description_length = str_length(description)) %>%
  mutate(description_length_scaled = description_length / max(description_length)) %>%
  mutate(overall_rating = ((q_overall - 1) / 4))

f = overall_rating ~ clipscore + (1|participant) + (1|description)
f = overall_rating ~ description_length_scaled + SPURTS_score + (1|participant) + (1|description)
# f = overall_rating ~ description_length_scaled + MIMA_score + (1|participant+description)

m = lmer(f, df_stats_blv_overall)
summary(m)


f = overall_rating ~ description_length_scaled + SPURTS_score
f = overall_rating ~ description_length_scaled
f = overall_rating ~ SPURTS_score

m = lm(f, df_stats_blv_overall)
summary(m)

```